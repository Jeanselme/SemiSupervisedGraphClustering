{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple example that allows to visualize the result of semi supervised graph clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example we use the MNIST dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits(n_class=10)\n",
    "data = digits.data\n",
    "label = digits.target\n",
    "classes = digits.target_names\n",
    "k = len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "def random_indices(list_points, number_indices):\n",
    "    \"\"\"\n",
    "        Generates a list of indices to apply on the constraint matrix\n",
    "        without redundancy\n",
    "        \n",
    "        Arguments:\n",
    "            list_points {List of Int / Int} -- Number of points in dataset or list of points to take into account\n",
    "            number_indices {Int} -- Number of indices needed\n",
    "\n",
    "        Returns:\n",
    "            List of pairs of coordinates\n",
    "    \"\"\"\n",
    "    if isinstance(list_points, int):\n",
    "        list_points = np.arange(list_points)\n",
    "\n",
    "    length = len(list_points)\n",
    "    indices = set()\n",
    "    while len(indices) < number_indices:\n",
    "        i = np.random.randint(length - 1)\n",
    "        j = np.random.randint(i + 1, length)\n",
    "        indices.add((list_points[i], list_points[j]))\n",
    "\n",
    "    return list(indices)\n",
    "\n",
    "def generate_constraint(labels, indices):\n",
    "    \"\"\"\n",
    "        Returns the sparse matrix of constraints\n",
    "\n",
    "        Arguments:\n",
    "            labels {Array n} -- Ground truth labels\n",
    "            indices {List of (i int, j int)} -- Indices to keep \n",
    "    \"\"\"\n",
    "    rows, cols, vals = [], [], []\n",
    "    for i, j in indices:\n",
    "        rows.extend([i, j])\n",
    "        cols.extend([j, i])\n",
    "        vals.extend([1 if (labels[i] == labels[j]) else -1] * 2)\n",
    "\n",
    "    return coo_matrix((vals, (rows, cols)), shape = (len(labels), len(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42) # For reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the constraints of all the points and subselect the training one, by selecting 100 constraints on 100 points randomly selected (cf remark 3 in readme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes all constraints\n",
    "ground_truth = 2 * np.equal.outer(label, label) - 1 \n",
    "np.fill_diagonal(ground_truth, 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subset of training points\n",
    "train_selection = np.random.choice(np.arange(len(label)), size = 100, replace = False)\n",
    "test_selection = [i for i in np.arange(len(label)) if i not in train_selection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes a subset of constraint using only training points\n",
    "random_index = random_indices(train_selection, 100)\n",
    "train_constraint = generate_constraint(label, random_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute affinity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example we compute one rbf kernel with the median initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucldist = euclidean_distances(data, data, squared=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affinity = rbf_kernel(data, gamma = 1./(np.median(eucldist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affinities = [rbf_kernel(data, gamma = 1./(np.median(eucldist)) * alpha) for alpha in [0.1, 0.5, 1, 5, 10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sskkmeans import ssKmeans, crossValidationSskmeans\n",
    "from KernelConstrainedKmeans.initialization import Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialization = Initialization(k, train_constraint).farthest_initialization(affinity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = len(digits) / (k * len(index_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignation = ssKmeans(affinity, initialization.copy(), \"ratio cut\", train_constraint * weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignation_cv = crossValidationSskmeans(affinities, k, \"ratio cut\", train_constraint * weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import v_measure_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to show that the algo allow to increase the performances of the clustering, we compute performances after initialization and after the kernel constrained kmeans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Performance on training : {:.2f}\".format(v_measure_score(label[train_selection], initialization[train_selection])))\n",
    "print(\"Performance on testing : {:.2f}\".format(v_measure_score(label[test_selection], initialization[test_selection])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Performance on training : {:.2f}\".format(v_measure_score(label[train_selection], assignation[train_selection])))\n",
    "print(\"Performance on testing : {:.2f}\".format(v_measure_score(label[test_selection], assignation[test_selection])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Performance on training : {:.2f}\".format(v_measure_score(label[train_selection], assignation_cv[train_selection])))\n",
    "print(\"Performance on testing : {:.2f}\".format(v_measure_score(label[test_selection], assignation_cv[test_selection])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computes a projection of the data and visualize the different results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE().fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(tsne[:,0], tsne[:, 1], c = label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(tsne[:,0], tsne[:, 1], c = assignation)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
